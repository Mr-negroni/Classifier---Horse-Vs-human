{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled9.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Uq1t-NXfKA2x"
      },
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "import zipfile\n",
        "url = \"https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\"\n",
        "file_name = \"horse-or-human.zip\"\n",
        "training_dir = 'horse-or-human/training/'\n",
        "urllib.request.urlretrieve(url, file_name)\n",
        "zip_ref = zipfile.ZipFile(file_name, 'r')\n",
        "zip_ref.extractall(training_dir)\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "F8aDXfvJKKUe"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tr_datagen = ImageDataGenerator(rescale = 1/255)\n",
        "tr_gen = tr_datagen.flow_from_directory('horse-or-human/training',target_size = (300,300),class_mode = 'binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8Wae7M2LT7z",
        "outputId": "edb169f4-52f2-4c1e-ed50-7b697408c60a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1027 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten,Conv2D,MaxPooling2D"
      ],
      "metadata": {
        "id": "pmL6YRxiLrEK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "model = Sequential([\n",
        "                    Conv2D(16,(3,3),activation = 'relu',input_shape = (300,300,3)),\n",
        "                    MaxPooling2D(2,2),\n",
        "                    Conv2D(32,(3,3),activation = 'relu'),\n",
        "                    MaxPooling2D(2,2),\n",
        "                    Conv2D(64,(3,3),activation = 'relu'),\n",
        "                    MaxPooling2D(2,2),\n",
        "                    Conv2D(64,(3,3),activation = 'relu'),\n",
        "                    MaxPooling2D(2,2),\n",
        "                    Conv2D(64,(3,3),activation = 'relu'),\n",
        "                    MaxPooling2D(2,2),\n",
        "                    Flatten(),\n",
        "                    Dense(units = 512,activation = tensorflow.nn.relu),\n",
        "                    Dense(units =1, activation = tensorflow.nn.sigmoid)\n",
        "])"
      ],
      "metadata": {
        "id": "NZr9c_3VMR1P"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss = 'binary_crossentropy',optimizer = 'adam',metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "oTCdqw9LM15v"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "histoy = model.fit_generator(tr_gen,epochs = 7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qtw7bJgRN1RB",
        "outputId": "d9a9cac9-b0c2-476b-b239-8dbd819aafce"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7\n",
            "33/33 [==============================] - 111s 3s/step - loss: 0.4443 - accuracy: 0.7575\n",
            "Epoch 2/7\n",
            "33/33 [==============================] - 96s 3s/step - loss: 0.1976 - accuracy: 0.9279\n",
            "Epoch 3/7\n",
            "33/33 [==============================] - 96s 3s/step - loss: 0.0655 - accuracy: 0.9737\n",
            "Epoch 4/7\n",
            "33/33 [==============================] - 97s 3s/step - loss: 0.0199 - accuracy: 0.9922\n",
            "Epoch 5/7\n",
            "33/33 [==============================] - 96s 3s/step - loss: 0.0060 - accuracy: 0.9981\n",
            "Epoch 6/7\n",
            "33/33 [==============================] - 97s 3s/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 7/7\n",
            "33/33 [==============================] - 96s 3s/step - loss: 5.9673e-04 - accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_url = \"https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\"\n",
        "validation_file_name = \"validation-horse-or-human.zip\"\n",
        "validation_dir = 'horse-or-human/validation/'\n",
        "urllib.request.urlretrieve(validation_url, validation_file_name)\n",
        "zip_ref = zipfile.ZipFile(validation_file_name, 'r')\n",
        "zip_ref.extractall(validation_dir)\n",
        "zip_ref.close()\n",
        "#Getting the Validation Set"
      ],
      "metadata": {
        "id": "mKV1WTErOV0Q"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_datagen = ImageDataGenerator(rescale = 1/255)\n",
        "validation_generator = validation_datagen.flow_from_directory('horse-or-human/validation',target_size = (300,300),class_mode = 'binary')\n",
        "history = model.fit_generator(tr_gen,epochs = 15,validation_data = validation_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BBLZScUP2NN",
        "outputId": "1bf8a7fe-28fe-4d92-9876-2bb55bf51a92"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 256 images belonging to 2 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "33/33 [==============================] - 103s 3s/step - loss: 6.8825e-05 - accuracy: 1.0000 - val_loss: 2.9858 - val_accuracy: 0.8398\n",
            "Epoch 2/15\n",
            "33/33 [==============================] - 103s 3s/step - loss: 6.3156e-05 - accuracy: 1.0000 - val_loss: 2.9207 - val_accuracy: 0.8398\n",
            "Epoch 3/15\n",
            "33/33 [==============================] - 101s 3s/step - loss: 4.6397e-05 - accuracy: 1.0000 - val_loss: 3.0109 - val_accuracy: 0.8398\n",
            "Epoch 4/15\n",
            "33/33 [==============================] - 100s 3s/step - loss: 3.9543e-05 - accuracy: 1.0000 - val_loss: 3.0861 - val_accuracy: 0.8398\n",
            "Epoch 5/15\n",
            "33/33 [==============================] - 102s 3s/step - loss: 3.5074e-05 - accuracy: 1.0000 - val_loss: 3.1033 - val_accuracy: 0.8398\n",
            "Epoch 6/15\n",
            "33/33 [==============================] - 101s 3s/step - loss: 2.9126e-05 - accuracy: 1.0000 - val_loss: 3.2226 - val_accuracy: 0.8359\n",
            "Epoch 7/15\n",
            "33/33 [==============================] - 102s 3s/step - loss: 2.6801e-05 - accuracy: 1.0000 - val_loss: 3.1552 - val_accuracy: 0.8398\n",
            "Epoch 8/15\n",
            "33/33 [==============================] - 101s 3s/step - loss: 2.3484e-05 - accuracy: 1.0000 - val_loss: 3.2323 - val_accuracy: 0.8398\n",
            "Epoch 9/15\n",
            "33/33 [==============================] - 101s 3s/step - loss: 2.0671e-05 - accuracy: 1.0000 - val_loss: 3.2653 - val_accuracy: 0.8398\n",
            "Epoch 10/15\n",
            "33/33 [==============================] - 102s 3s/step - loss: 1.9207e-05 - accuracy: 1.0000 - val_loss: 3.3146 - val_accuracy: 0.8359\n",
            "Epoch 11/15\n",
            "33/33 [==============================] - 101s 3s/step - loss: 1.6894e-05 - accuracy: 1.0000 - val_loss: 3.3261 - val_accuracy: 0.8359\n",
            "Epoch 12/15\n",
            "33/33 [==============================] - 102s 3s/step - loss: 1.5898e-05 - accuracy: 1.0000 - val_loss: 3.2457 - val_accuracy: 0.8398\n",
            "Epoch 13/15\n",
            "33/33 [==============================] - 101s 3s/step - loss: 1.4385e-05 - accuracy: 1.0000 - val_loss: 3.5223 - val_accuracy: 0.8320\n",
            "Epoch 14/15\n",
            "33/33 [==============================] - 101s 3s/step - loss: 1.2839e-05 - accuracy: 1.0000 - val_loss: 3.4928 - val_accuracy: 0.8320\n",
            "Epoch 15/15\n",
            "33/33 [==============================] - 100s 3s/step - loss: 1.1554e-05 - accuracy: 1.0000 - val_loss: 3.4374 - val_accuracy: 0.8359\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "qfEWr9GaSlna"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = image.load_img('man-g33a713a36_640.jpg',target_size = (300,300))"
      ],
      "metadata": {
        "id": "RurDM0FBWfBp"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = image.img_to_array(img)"
      ],
      "metadata": {
        "id": "cOz0MhdlWueZ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuZMN700W4Ud",
        "outputId": "af128186-c472-44fa-fecb-5ae9f9d03343"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300, 300, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.expand_dims(x,axis=0)\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sipjySfEXbLf",
        "outputId": "4018483a-9581-4f29-f142-cfcd31cc9115"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 300, 300, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_tensor = np.vstack([x])\n",
        "image_tensor.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ht-Qj4BmXpHC",
        "outputId": "abd891b7-cc93-4bfa-8d45-52685dc3b0ec"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 300, 300, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classification = model.predict(image_tensor)"
      ],
      "metadata": {
        "id": "citC7y28Xzal"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAyMW4hfX6vJ",
        "outputId": "5f5017f3-2c38-45ac-f44b-1c0fb97e5968"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQRnRcL6X8aL",
        "outputId": "d5606283-0281-4156-8f59-bc5fc8280ad5"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if classification[0]<0.5:\n",
        "  print('Human')\n",
        "else :\n",
        "  print('horse')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFFIbRN_YLPP",
        "outputId": "dcb3bada-0cc3-47c4-c701-c8cabadce120"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5tvSH8iFYQjd"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "24e-qPEPfF-S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}